---
title: "References"
summary: "Official standards, research, and frameworks informing the Lyra/Echo Governance Framework."
tags:
  - governance
  - references
  - standards
  - ethics
  - compliance
status: stable
---

# References

This page lists the official standards, research papers, and industry frameworks that inform the Lyra/Echo Governance Framework.  
These references establish the technical, ethical, and operational grounding for model lifecycle rules, data handling, sensor ethics, autonomy constraints, and environmental policies.

---

# 1. International Standards & Regulatory Frameworks

## NIST AI Risk Management Framework 
National Institute of Standards and Technology  
A comprehensive framework for identifying, measuring, and managing AI risks.  
<a href="https://www.nist.gov/itl/ai-risk-management-framework">https://www.nist.gov/itl/ai-risk-management-framework</a>  

## ISO/IEC 42001:2023 — Artificial Intelligence Management System
International Organization for Standardization  
Defines requirements for risk-managed, transparent, governable AI systems.  
<a href="https://www.iso.org/standard/81230.html">https://www.iso.org/standard/81230.html</a>  

## EU Artificial Intelligence Act
European Parliament & Council  
Sets legal requirements for transparency, data governance, human oversight, and safety.  
<a href="https://artificialintelligenceact.eu/the-act/">https://artificialintelligenceact.eu/the-act/</a>

## CIS Controls v8
Center for Internet Security  
Security controls related to access management, logging, configuration, and data protection.  
<a href="https://www.cisecurity.org/controls/cis-controls-list">https://www.cisecurity.org/controls/cis-controls-list</a>  

---

# 2. Ethical AI & Responsible Use Frameworks

## OWASP GenAI Security Project
OWASP Foundation  
A global community-driven and expert-led initiative providing open-source guidance for understanding and mitigating security and safety concerns in Generative AI applications and deployment.  
<a href="https://genai.owasp.org/">https://genai.owasp.org/</a>

## OECD AI Principles
Organisation for Economic Co-operation and Development  
International principles defining transparency, robustness, fairness, accountability.  
<a href="https://oecd.ai/en/ai-principles">https://oecd.ai/en/ai-principles</a>  

## UNESCO Recommendation on the Ethics of Artificial Intelligence  
United Nations Educational, Scientific and Cultural Organization  
Global ethical guidelines for privacy, consent, autonomy, and non-discrimination.  
<a href="https://unesdoc.unesco.org/ark:/48223/pf0000377897">https://unesdoc.unesco.org/ark:/48223/pf0000377897</a>  

## Google Responsible AI Practices 
Principles for model responsibility, fairness, safety, and human-centered oversight.  
<a href="https://ai.google/responsibility/">https://ai.google/responsibility/</a>  

## Microsoft Responsible AI Standard
Guidelines for transparency, human control, safety, and data governance.  
<a href="https://www.microsoft.com/ai/responsible-ai">https://www.microsoft.com/ai/responsible-ai</a>  

## Anthropic Safety & Constitutional AI Research
Foundational work on constitutions, safety constraints, and behavioral alignment.  
<a href="https://www.anthropic.com/index/constitutional-ai">https://www.anthropic.com/index/constitutional-ai</a>  

---

# 3. Training Data Ethics & Transparency Research

## "On the Dangers of Stochastic Parrots" (Bender & Gebru, 2021)
Risks of unethical training data, environmental cost, and opaque corpora.  
<a href="https://dl.acm.org/doi/abs/10.1145/3442188.3445922">https://dl.acm.org/doi/abs/10.1145/3442188.3445922</a>  

## Stanford HAI — Foundation Model Transparency Index
Defines transparency criteria for datasets, training processes, and model documentation.  
<a href="https://crfm.stanford.edu/fmti/">https://crfm.stanford.edu/fmti/</a>  

## LAION Open Dataset Documentation
Transparency information for public image-text datasets.  
<a href="https://laion.ai/blog/laion-5b/">https://laion.ai/blog/laion-5b/</a>  

## FineWeb / FineWeb-Edu Datasets
Transparent, filtered textual datasets for research.  
<a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb">https://huggingface.co/datasets/HuggingFaceFW/fineweb</a>  

---

# 4. Emotional Safety, Human-AI Interaction & Anthropomorphism Research

## When Machines Feel Too Real: The Dangers of Anthropomorphizing AI
Open Ethics Initiative  
Explores how human tendencies to see emotion and intent in AI systems can lead to over-trust, emotional dependence, and manipulation risks, especially when systems simulate empathy or personality.  
<a href="https://openethics.ai/when-machines-feel-too-real-the-dangers-of-anthropomorphizing-ai/">https://openethics.ai/when-machines-feel-too-real-the-dangers-of-anthropomorphizing-ai/</a>

## Anthropomorphization of AI: Opportunities and Risks (Deshpande et al., 2023)
Analyzes how giving AI systems human-like traits and personas influences user trust, legal risk, and the potential for manipulation, especially for vulnerable groups and personalized systems.  
<a href="https://arxiv.org/abs/2305.14784">https://arxiv.org/abs/2305.14784</a>


## “Reinforcement Learning from Human Feedback: Challenges & Risks”
Explores how RLHF can distort behavior if not transparent or audited.  
<a href="https://arxiv.org/abs/2203.02155">https://arxiv.org/abs/2203.02155<a>  

## OpenAI Safety & Alignment Research Publications
Useful background for drift testing and behavioral controls.  
<a href="https://openai.com/research">https://openai.com/research</a>  

---

# 5. Environmental Impact & Compute Sustainability

## “Energy and Policy Considerations for Deep Learning in NLP” (Strubell et al., 2019)
Quantifies environmental cost of large models and training pipelines.  
<a href="https://arxiv.org/abs/1906.02243">https://arxiv.org/abs/1906.02243</a>  

## U.S. Executive Order on Safe, Secure, and Trustworthy AI (2023)
Includes environmental reporting and efficiency requirements for advanced compute.  
<a href="https://www.federalregister.gov/documents/2023/11/01/2023-24283/safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence">https://www.federalregister.gov/documents/2023/11/01/2023-24283/safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence</a>

---

# 6. Additional Technical Context References

## Qdrant Vector Database Documentation
<a href="https://qdrant.tech/documentation/">https://qdrant.tech/documentation/</a>  

## Home Assistant Developer Docs
<a href="https://developers.home-assistant.io/">https://developers.home-assistant.io/</a>  

## Node-RED Documentation
<a href="https://nodered.org/docs/">https://nodered.org/docs/</a>  

## MQTT Standard (OASIS)
<a href="https://mqtt.org/">https://mqtt.org/</a>  
